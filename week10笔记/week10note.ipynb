{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn 核心代码与操作全流程\n",
    "\n",
    "```python\n",
    "# 一、基础数据准备与加载\n",
    "## 1. 数据格式与示例数据集（鸢尾花）\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target  # 特征矩阵 [n_samples, n_features] 与标签\n",
    "print(f\"数据集形状: {iris.data.shape}\")  # (150, 4)\n",
    "print(f\"类别名称: {iris.target_names}\")  # ['setosa' 'versicolor' 'virginica']\n",
    "\n",
    "\n",
    "# 二、监督学习（Supervised Learning）\n",
    "## 1. 数据集拆分（为模型训练做准备）\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 划分训练集（75%）和测试集（25%）\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0\n",
    ")\n",
    "\n",
    "## 2. K近邻分类器（KNeighborsClassifier）\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 初始化模型（1-近邻）\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "# 训练模型（所有Estimator均通过fit方法训练）\n",
    "knn.fit(X_train, y_train)\n",
    "# 预测测试集\n",
    "predicted_knn = knn.predict(X_test)\n",
    "\n",
    "## 3. 高斯朴素贝叶斯（GaussianNB）\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# 初始化并训练模型\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "# 预测\n",
    "predicted_gnb = clf.predict(X_test)\n",
    "\n",
    "## 4. 分类性能评估\n",
    "from sklearn import metrics\n",
    "\n",
    "# K近邻分类评估\n",
    "print(\"K近邻分类报告:\")\n",
    "print(metrics.classification_report(y_test, predicted_knn))\n",
    "print(\"混淆矩阵:\")\n",
    "print(metrics.confusion_matrix(y_test, predicted_knn))\n",
    "\n",
    "# 高斯朴素贝叶斯评估\n",
    "print(\"\\n高斯朴素贝叶斯分类报告:\")\n",
    "print(metrics.classification_report(y_test, predicted_gnb))\n",
    "\n",
    "## 5. 回归问题（以线性回归为例）\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 假设使用鸢尾花数据的一个特征预测另一个特征（示例）\n",
    "X_reg = X[:, 0].reshape(-1, 1)  # 取第一个特征作为输入\n",
    "y_reg = X[:, 1]  # 取第二个特征作为目标\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.25, random_state=0\n",
    ")\n",
    "\n",
    "# 训练线性回归模型\n",
    "model = LinearRegression()\n",
    "model.fit(X_reg_train, y_reg_train)\n",
    "predicted_reg = model.predict(X_reg_test)\n",
    "\n",
    "# 回归性能评估（均方根误差）\n",
    "rms = np.sqrt(np.mean((predicted_reg - y_reg_test) **2))\n",
    "print(f\"\\n线性回归均方根误差: {rms:.4f}\")\n",
    "\n",
    "## 6. 梯度提升树回归\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# 训练梯度提升树模型\n",
    "reg = GradientBoostingRegressor()\n",
    "reg.fit(X_reg_train, y_reg_train)\n",
    "predicted_gbr = reg.predict(X_reg_test)\n",
    "gbr_rms = np.sqrt(np.mean((predicted_gbr - y_reg_test)** 2))\n",
    "print(f\"梯度提升树回归均方根误差: {gbr_rms:.4f}\")\n",
    "\n",
    "\n",
    "# 三、无监督学习（Unsupervised Learning）\n",
    "## 1. 主成分分析（PCA）降维\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 初始化PCA模型（降为2维）\n",
    "pca = PCA(n_components=2)\n",
    "# 拟合并转换数据（无监督学习常用fit_transform）\n",
    "X_pca = pca.fit_transform(X)\n",
    "print(f\"\\nPCA解释方差比例: {pca.explained_variance_ratio_}\")  # 前两主成分的方差占比\n",
    "\n",
    "## 2. t-SNE嵌入（高维数据可视化）\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# 初始化t-SNE模型\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "# t-SNE仅支持fit_transform，无法对新数据增量转换\n",
    "X_2d = tsne.fit_transform(X)\n",
    "\n",
    "\n",
    "# 四、模型优化与验证\n",
    "## 1. 交叉验证（以朴素贝叶斯为例）\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 5折交叉验证\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(f\"\\n交叉验证得分: {scores}\")\n",
    "print(f\"平均得分: {np.mean(scores):.4f}\")\n",
    "\n",
    "## 2. 超参数优化（网格搜索）\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# 定义参数网格（Ridge回归的正则化系数alpha）\n",
    "param_grid = {'alpha': np.logspace(-3, -1, 30)}\n",
    "# 初始化网格搜索（3折交叉验证）\n",
    "gscv = GridSearchCV(Ridge(), param_grid, cv=3)\n",
    "gscv.fit(X_train, y_train)\n",
    "print(f\"\\n网格搜索最优参数: {gscv.best_params_}\")\n",
    "\n",
    "## 3. 内置交叉验证模型（RidgeCV）\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# 自动选择最优alpha（内置交叉验证）\n",
    "alphas = np.logspace(-3, 1, 10)\n",
    "model_ridgecv = RidgeCV(alphas=alphas, cv=3)\n",
    "model_ridgecv.fit(X_train, y_train)\n",
    "print(f\"RidgeCV最优正则化系数: {model_ridgecv.alpha_}\")\n",
    "\n",
    "## 4. 正则化效果示例（以多项式拟合为例）\n",
    "# 假设X_poly为多项式特征，对比不同阶数的拟合效果\n",
    "# 4阶多项式比9阶更简单，过拟合风险更低（正则化核心思想）\n",
    "\n",
    "\n",
    "# 五、管道工具（串联特征工程与模型）\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# 构建多项式特征+线性回归的管道\n",
    "pipeline = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "# 管道直接调用fit和predict，内部自动处理特征转换\n",
    "pipeline.fit(X_reg_train, y_reg_train)\n",
    "pipeline_pred = pipeline.predict(X_reg_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
